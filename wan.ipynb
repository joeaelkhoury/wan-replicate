{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "# install WAN2.1 code\n",
    "!git clone https://github.com/Wan-Video/Wan2.1.git\n",
    "\n",
    "# Commits on Mar 7, 2025\n",
    "%cd /content/Wan2.1\n",
    "!git checkout b58b7c573776b76b6fe8d36086590e033173f9b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/Wan2.1\n",
    "\n",
    "# !pip install -r requirements.txt\n",
    "!pip install ftfy dashscope\n",
    "!pip uninstall diffusers -y\n",
    "!pip install 'git+https://github.com/huggingface/diffusers.git@26149c0ecda67587ffd51f1a91c888388f83253b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# check versions\n",
    "!python --version\n",
    "\n",
    "!pip list | egrep 'torch|ftfy|dashscope|diffusers|transformers'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/Wan2.1\n",
    "\n",
    "from IPython.display import Video\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from diffusers.utils import export_to_video, load_image\n",
    "from diffusers import AutoencoderKLWan, WanPipeline, WanImageToVideoPipeline\n",
    "from diffusers.schedulers.scheduling_unipc_multistep import UniPCMultistepScheduler\n",
    "\n",
    "from transformers import CLIPVisionModel\n",
    "\n",
    "# set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device is', device)\n",
    "\n",
    "!mkdir outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Text-to-Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Wan-AI/Wan2.1-T2V-14B-Diffusers または Wan-AI/Wan2.1-T2V-1.3B-Diffusers のモデルIDを指定\n",
    "model_id = \"Wan-AI/Wan2.1-T2V-1.3B-Diffusers\"\n",
    "\n",
    "# VAE（変分オートエンコーダー）の初期化\n",
    "vae = AutoencoderKLWan.from_pretrained(model_id, subfolder=\"vae\", torch_dtype=torch.float16)\n",
    "\n",
    "# フローシフトの設定：720Pの場合は5.0、480Pの場合は3.0\n",
    "flow_shift = 5.0\n",
    "\n",
    "# スケジューラの設定：フロー予測を行うUniPCMultistepSchedulerを使用\n",
    "scheduler = UniPCMultistepScheduler(\n",
    "    prediction_type='flow_prediction', \n",
    "    use_flow_sigmas=True, \n",
    "    num_train_timesteps=1000, \n",
    "    flow_shift=flow_shift)\n",
    "\n",
    "# パイプラインの初期化\n",
    "pipe = WanPipeline.from_pretrained(\n",
    "    model_id, \n",
    "    vae=vae, \n",
    "    torch_dtype=torch.bfloat16)\n",
    "pipe.scheduler = scheduler\n",
    "pipe.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"Beautiful robot man walking, High Definition HD, High Detail, UHD Pen and Ink Art, Perfect Composition, Detailed Structure, Crazy Octane Rendering, Photorealism Concept Art,3D Cinematography, Perfect Light, 3D -rendering, famous outstanding typography, 3d render, cinematic.\"\n",
    "negative_prompt = \"Low quality, blurry, pixelated, distorted, deformed, unrealistic, unnatural lighting, poor resolution, artifacts, glitches, low detail.\"\n",
    "seed = 12\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
    "\n",
    "output = pipe(\n",
    "     prompt           = prompt,\n",
    "     negative_prompt  = negative_prompt,\n",
    "     height           = 720,\n",
    "     width            = 1280,\n",
    "     num_frames       = 81,\n",
    "     guidance_scale   = 5.0,\n",
    "     generator = generator\n",
    "    ).frames[0]\n",
    "\n",
    "export_to_video(output, \"./outputs/t2v_output.mp4\", fps=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Video(\"./outputs/t2v_output.mp4\", embed=True, height=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"桜の花びらが舞い散る姫路城\"\n",
    "negative_prompt = \"低画質\"\n",
    "seed = 12\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
    "\n",
    "output = pipe(\n",
    "     prompt           = prompt,\n",
    "     negative_prompt  = negative_prompt,\n",
    "     height           = 720,\n",
    "     width            = 1280,\n",
    "     num_frames       = 81,\n",
    "     guidance_scale   = 5.0,\n",
    "     generator = generator\n",
    "    ).frames[0]\n",
    "\n",
    "export_to_video(output, \"./outputs/t2v_output_jp.mp4\", fps=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Video(\"./outputs/t2v_output_jp.mp4\", embed=True, height=420)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Image to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# release memory\n",
    "del pipe\n",
    "del scheduler\n",
    "del vae\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# model id\n",
    "# Wan-AI/Wan2.1-I2V-14B-480P-Diffusers or Wan-AI/Wan2.1-I2V-14B-720P-Diffusers\n",
    "model_id = \"Wan-AI/Wan2.1-I2V-14B-480P-Diffusers\"\n",
    "\n",
    "# 画像エンコーダのロード\n",
    "image_encoder = CLIPVisionModel.from_pretrained(\n",
    "    model_id, \n",
    "    subfolder=\"image_encoder\", \n",
    "    torch_dtype=torch.float32)\n",
    "\n",
    "# VAE(Variational Autoencoder)のロード\n",
    "vae = AutoencoderKLWan.from_pretrained(\n",
    "    model_id, \n",
    "    subfolder=\"vae\", \n",
    "    torch_dtype=torch.float32)\n",
    "\n",
    "# image-to-video pipelineのセットアップ\n",
    "pipe = WanImageToVideoPipeline.from_pretrained(\n",
    "    model_id, \n",
    "    vae=vae, \n",
    "    image_encoder=image_encoder, \n",
    "    torch_dtype=torch.bfloat16)\n",
    "\n",
    "\n",
    "# CPUオフロードを有効化(メモリ節約のため)\n",
    "pipe.enable_model_cpu_offload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ウェブから画像を読み込む\n",
    "image = load_image(\n",
    "    \"https://user0514.cdnw.net/shared/img/thumb/yuta_240513_031_TP_V4.jpg\"\n",
    ")\n",
    "\n",
    "# 画像の最大面積を制限(832*480ピクセル)\n",
    "max_area = 832*480\n",
    "# 画像の縦横比を計算(元のアスペクト比を維持するため)\n",
    "aspect_ratio = image.height / image.width\n",
    "# 画像のリサイズ時の調整値(モデルのスケールファクターとパッチサイズを考慮)\n",
    "mod_value = pipe.vae_scale_factor_spatial * pipe.transformer.config.patch_size[1]\n",
    "# 高さと幅を計算(アスペクト比を維持しつつ、最大面積を超えないように調整)\n",
    "height = round(np.sqrt(max_area * aspect_ratio)) // mod_value * mod_value\n",
    "width = round(np.sqrt(max_area / aspect_ratio)) // mod_value * mod_value\n",
    "# 計算したサイズにリサイズ\n",
    "image = image.resize((width, height))\n",
    "\n",
    "prompt = \"Plane taking off. Cinematic, 4K\"\n",
    "negative_prompt = \"low quality\"\n",
    "\n",
    "# set seed\n",
    "seed = 12\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
    "\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "output = pipe(\n",
    "    image           = image,\n",
    "    prompt          = prompt,\n",
    "    negative_prompt = negative_prompt,\n",
    "    height          = height,\n",
    "    width           = width,\n",
    "    num_frames      = 81,\n",
    "    guidance_scale  = 5.0,\n",
    "    generator = generator,\n",
    ").frames[0]\n",
    "\n",
    "export_to_video(output, \"./outputs/i2v_output.mp4\", fps=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Video(\"./outputs/i2v_output.mp4\", embed=True, height=420)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
